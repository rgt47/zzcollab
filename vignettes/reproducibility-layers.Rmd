---
title: "Layered Approach to Reproducibility"
author: "ZZCOLLAB Development Team"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Layered Approach to Reproducibility}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

Reproducibility in computational research exists on a spectrum. This guide
presents a progressive, four-level approach to reproducibility using ZZCOLLAB,
allowing researchers to adopt tools incrementally based on project needs and
collaboration requirements.

Each level adds specific guarantees about reproducibility while introducing
additional complexity. Understanding the tradeoffs enables informed decisions
about appropriate reproducibility investments for different research contexts.

## The Four Levels

1. **Level 1: Basic R Project** - Manual package management
2. **Level 2: renv** - Automated dependency tracking
3. **Level 3: renv + Docker** - Complete environment isolation
4. **Level 4: renv + Docker + CI/CD** - Automated validation

# Level 1: Basic R Project

## What This Provides

A standard R project structure with manual package management. Packages are
installed in the user's global R library using `install.packages()`.

## Project Structure

```
my-project/
├── .Rproj
├── R/
│   └── functions.R
├── data/
│   └── raw_data/
├── scripts/
│   └── 01_analysis.R
└── README.md
```

## Setup

```r
# Create project in RStudio: File > New Project > New Directory > New Project
# Or from command line:
dir.create("my-project")
setwd("my-project")
dir.create(c("R", "data/raw_data", "scripts"))
```

## Typical Workflow

```r
# Install packages globally
install.packages("dplyr")
install.packages("ggplot2")

# Load packages in scripts
library(dplyr)
library(ggplot2)

# Perform analysis
data %>%
  filter(condition) %>%
  ggplot(aes(x, y)) + geom_point()
```

## Pros

- **Simple**: No additional tools or concepts to learn
- **Fast setup**: Start coding immediately
- **Flexible**: Easy to experiment with new packages
- **Low overhead**: No configuration files to maintain
- **Standard workflow**: Familiar to most R users

## Cons

- **No version tracking**: Package versions not recorded
- **Update fragility**: `update.packages()` can break existing code
- **Collaboration friction**: "Works on my machine" problems common
- **Time-dependent failure**: Code may stop working months later due to
  package updates
- **Implicit dependencies**: No record of which packages are actually required
- **System-dependent**: Results may differ across operating systems

## When to Use Level 1

Appropriate for:

- Personal exploratory analysis
- Short-lived projects (< 1 week)
- Learning R and packages
- Quick prototypes not intended for sharing
- Analysis you won't revisit

Not appropriate for:

- Published research
- Team collaboration
- Long-term projects
- Code you'll share with others

## Reproducibility Failure Example

```r
# January 2024: Code works
library(dplyr)
data %>% select(x, y) %>% filter(x > 0)  # dplyr 1.1.0

# June 2024: After update.packages()
# dplyr 1.2.0 introduces breaking change
# Code produces different results or fails
```

# Level 2: renv (Dependency Management)

## What This Adds

The `renv` package creates project-specific R libraries and records exact
package versions in a lockfile. Each project has isolated dependencies
independent of the global R library.

## Additional Structure

```
my-project/
├── .Rproj
├── renv/                    # Project-specific package library
├── renv.lock               # Exact package versions (auto-generated)
├── .Rprofile               # Auto-activates renv (auto-generated)
├── R/
├── data/
├── scripts/
└── README.md
```

## Setup

```r
# Initialize renv in existing project
install.packages("renv")  # One-time global install
renv::init()

# Or create new project with ZZCOLLAB
zzcollab -M  # Minimal mode includes renv
```

## Typical Workflow

```r
# Install packages (now project-specific)
renv::install("dplyr")
renv::install("ggplot2")

# Work normally
library(dplyr)
library(ggplot2)

# Save dependency state
renv::snapshot()  # Updates renv.lock

# Collaborator restores exact versions
renv::restore()   # Installs from renv.lock
```

## Pros

- **Version locking**: Exact package versions recorded in renv.lock
- **Project isolation**: Projects don't interfere with each other
- **Collaboration support**: Team members get identical package versions
- **Explicit dependencies**: renv.lock documents all required packages
- **Time resilience**: Project works months/years later with same packages
- **Safe updates**: Test updates in isolation before committing
- **Minimal learning curve**: Familiar R workflow with `renv::install()`

## Cons

- **Additional storage**: Each project stores its own package copies
  (~100-500MB typical)
- **Initial setup time**: First `renv::restore()` downloads all packages
- **Snapshot discipline**: Must remember `renv::snapshot()` after package
  changes
- **R version dependency**: Still depends on user's R version
- **System library dependency**: Still depends on system libraries
  (gdal, geos, etc.)
- **Platform differences**: Windows vs Mac vs Linux can still cause issues

## When to Use Level 2

Appropriate for:

- Research projects intended for publication
- Team collaboration (2+ researchers)
- Long-term projects (> 1 month)
- Code shared publicly
- Reproducible analysis workflows

Still insufficient for:

- Cross-platform guarantees (Windows/Mac/Linux differences)
- System library dependencies (geospatial, databases)
- Complete environment isolation
- Exact R version requirements

## Reproducibility Guarantee

**Guaranteed**: Same R package versions across users/time

**Not guaranteed**: Same R version, same system libraries, same OS

## Example Workflow

```r
# Day 1: Start project
renv::init()
renv::install("tidyverse")
renv::snapshot()

# Day 30: Add new analysis
renv::install("lme4")
# ... write code ...
renv::snapshot()  # Don't forget!

# Year 2: Collaborator joins
git clone project
# In R:
renv::restore()  # Gets exact package versions from Day 30
```

# Level 3: renv + Docker (Complete Environment)

## What This Adds

Docker containers provide complete environment isolation including R version,
system libraries, and operating system. Everything runs in an identical Linux
environment regardless of host operating system.

## Additional Structure

```
my-project/
├── .Rproj
├── renv/
├── renv.lock
├── Dockerfile              # Environment definition
├── docker-compose.yml      # Container orchestration
├── .dockerignore           # Files to exclude from container
├── Makefile                # Convenient Docker commands
├── R/
├── data/
├── scripts/
└── README.md
```

## Setup

```bash
# Create project with Docker environment
zzcollab -M -D ~/dotfiles

# Or add Docker to existing renv project
# (requires manual Dockerfile creation)
```

## Typical Workflow

```bash
# Start development environment
make docker-zsh

# Now inside container (identical Linux environment)
R
> renv::install("tidyverse")
> # ... work normally ...
> renv::snapshot()
> quit()

# Exit container
exit

# Collaborator gets identical environment
git clone project
make docker-zsh  # Builds identical container
```

## Pros

- **Complete isolation**: R version, packages, system libraries all controlled
- **Cross-platform consistency**: Same environment on Windows/Mac/Linux
- **System dependency management**: GDAL, GEOS, database drivers included
- **Reproducible system state**: Dockerfile version-controls entire environment
- **Development/production parity**: Same environment locally and on servers
- **Easy collaboration**: "Pull and run" - no local R installation needed
- **Multiple R versions**: Different projects can use different R versions

## Cons

- **Storage overhead**: Docker images 800MB-3GB per project
- **Learning curve**: Docker concepts (images, containers, volumes)
- **Initial setup time**: Building Docker image (2-20 minutes depending on mode)
- **Resource usage**: Docker daemon must run in background
- **File permission complexity**: User IDs can cause permission issues
- **Slower package installation**: First install in container takes longer
- **Platform limitations**: ARM64 (Apple Silicon) vs AMD64 compatibility issues

## When to Use Level 3

Appropriate for:

- Cross-platform collaboration (Windows/Mac/Linux teams)
- Projects with system dependencies (geospatial, databases)
- Research requiring exact R version specification
- Complex environment dependencies
- Production deployment of analysis pipelines
- Long-term archival (10+ years)

Overkill for:

- Solo projects on single platform
- Simple analysis with few dependencies
- Short-term exploratory work

## Reproducibility Guarantee

**Guaranteed**: Same R version, same packages, same system libraries, same OS

**Not guaranteed**: Automated validation of correctness

## Example Workflow

```bash
# Team lead creates environment
zzcollab -i -t mylab -p climate-study -S -D ~/dotfiles

# Dockerfile specifies:
# - R version: 4.3.1
# - System libraries: gdal, geos, netcdf
# - Base packages: tidyverse, sf, raster

# Team member joins
git clone https://github.com/mylab/climate-study
cd climate-study
make docker-zsh  # Builds identical environment

# Inside container - everyone has same environment
R --version  # R version 4.3.1
sf::sf_extSoftVersion()  # GDAL 3.6.2 (same for everyone)
```

## Docker Build Modes

ZZCOLLAB provides four build modes to balance build time and capabilities:

```bash
# Minimal: Ultra-fast (3 packages, ~30s)
zzcollab -M -D ~/dotfiles

# Fast: Development essentials (9 packages, 2-3 min)
zzcollab -F -D ~/dotfiles

# Standard: Balanced (17 packages, 4-6 min) [default]
zzcollab -S -D ~/dotfiles

# Comprehensive: Full ecosystem (47+ packages, 15-20 min)
zzcollab -C -D ~/dotfiles
```

# Level 4: renv + Docker + CI/CD (Automated Validation)

## What This Adds

Continuous Integration/Continuous Deployment (CI/CD) automatically validates
that your code works in a clean environment on every commit. GitHub Actions
(or similar) run tests, checks, and builds to catch errors early.

## Additional Structure

```
my-project/
├── .Rproj
├── renv/
├── renv.lock
├── Dockerfile
├── docker-compose.yml
├── .github/
│   └── workflows/
│       ├── r-package.yml           # R package validation
│       └── render-paper.yml        # Manuscript rendering
├── validate_package_environment.R  # Dependency validation
├── tests/
│   └── testthat/
│       └── test-analysis.R         # Automated tests
├── Makefile
├── R/
├── data/
├── scripts/
└── README.md
```

## Setup

```bash
# Create project with CI/CD workflows
zzcollab -S -D ~/dotfiles -G  # -G creates GitHub repo

# GitHub Actions workflows automatically created
```

## Typical Workflow

```bash
# Develop locally
make docker-zsh
# ... work in container ...
exit

# Validate before committing
Rscript validate_package_environment.R --quiet --fail-on-issues
make docker-test

# Commit and push
git add .
git commit -m "Add climate model analysis"
git push

# GitHub Actions automatically:
# 1. Builds Docker container from scratch
# 2. Validates package dependencies
# 3. Runs R CMD check
# 4. Executes test suite
# 5. Renders manuscripts
# 6. Reports failures via email
```

## Pros

- **Automated validation**: Every commit tested automatically
- **Clean environment testing**: Catches "works on my machine" problems
- **Team notification**: Everyone notified when code breaks
- **Prevents regressions**: Tests ensure new code doesn't break old code
- **Documentation validation**: Ensures examples in documentation work
- **Deployment automation**: Can auto-deploy working versions
- **Confidence in main branch**: Main branch always in working state
- **Newcomer safety**: Contributors can't accidentally break the project

## Cons

- **Setup complexity**: GitHub Actions YAML syntax learning curve
- **Build time overhead**: Full validation takes 5-20 minutes per commit
- **GitHub dependency**: Requires GitHub (or GitLab, etc.)
- **Resource limits**: Free tier has monthly minute limits
- **Debugging difficulty**: CI failures can be harder to debug than local errors
- **Over-testing risk**: Running tests on trivial commits wastes resources
- **Notification fatigue**: Failed builds generate email notifications

## When to Use Level 4

Appropriate for:

- Team projects (3+ collaborators)
- Open source packages intended for CRAN
- Production analysis pipelines
- Research with frequent updates
- Projects with complex test suites
- Collaborative papers with multiple authors

Overkill for:

- Solo exploratory analysis
- Stable projects with infrequent changes
- Simple scripts without tests

## Reproducibility Guarantee

**Guaranteed**: Code works in clean environment on every commit

**Validated**: Package dependencies, test suite, documentation examples

## GitHub Actions Workflows

ZZCOLLAB creates two standard workflows:

### r-package.yml (Core Validation)

```yaml
# Runs on: every push, every pull request
# Validates:
#   - Package dependencies synchronized (validate_package_environment.R)
#   - R CMD check passes
#   - Test suite passes
#   - Project structure valid
```

### render-paper.yml (Manuscript)

```yaml
# Runs on: every push to main branch
# Produces:
#   - Rendered manuscript PDF/HTML
#   - Uploaded as artifact
#   - Available for download
```

## Example Workflow

```bash
# Day 1: Setup with CI/CD
zzcollab -i -t mylab -p paper2024 -S -D ~/dotfiles -G

# Automatically created GitHub repo with Actions enabled

# Day 5: Add analysis code
make docker-zsh
# ... develop code ...
# ... write tests in tests/testthat/ ...
exit

# Validate locally first
Rscript validate_package_environment.R --quiet
make docker-test

# Commit and push
git add .
git commit -m "Add primary analysis"
git push

# GitHub Actions runs automatically:
# - Builds Docker container
# - Validates dependencies
# - Runs all tests
# - Success: green checkmark on commit
# - Failure: email notification with logs

# Day 30: Collaborator contributes
# Opens pull request
# GitHub Actions validates their code before merge
# Maintainer reviews with confidence tests passed
```

## CI/CD Best Practices

**Write tests incrementally**:
```r
# tests/testthat/test-data-preparation.R
test_that("prepare_data removes missing values", {
  raw <- data.frame(x = c(1, NA, 3), y = c(4, 5, 6))
  result <- prepare_data(raw)
  expect_equal(nrow(result), 2)
  expect_false(anyNA(result))
})
```

**Validate dependencies before committing**:
```bash
# Check that all packages used in code are declared
Rscript validate_package_environment.R --quiet --fail-on-issues

# This prevents CI failures due to missing packages
```

**Use descriptive commit messages**:
```bash
# Good: Helps understand CI failure context
git commit -m "Add bootstrapping to uncertainty analysis"

# Bad: Unclear what CI is testing
git commit -m "Update code"
```

# Choosing the Right Level

## Decision Framework

### Solo Researcher, Exploratory Phase
**Recommendation**: Level 1 or Level 2

- Level 1 if analysis is temporary (< 1 week)
- Level 2 if you might return to this analysis

### Solo Researcher, Publication-Bound
**Recommendation**: Level 2 or Level 3

- Level 2 if Windows/Mac-only collaboration
- Level 3 if cross-platform or system dependencies

### Small Team (2-4 people), Same Platform
**Recommendation**: Level 2

- renv ensures package consistency
- Docker overhead not justified for same-platform teams

### Small Team (2-4 people), Mixed Platforms
**Recommendation**: Level 3

- Docker eliminates Windows/Mac/Linux differences
- System dependencies handled automatically

### Large Team (5+ people)
**Recommendation**: Level 4

- Automated testing prevents integration problems
- CI/CD essential for coordinating multiple contributors

### Package Development for CRAN
**Recommendation**: Level 4

- R CMD check must pass on multiple platforms
- Automated testing required for maintenance

## Cost-Benefit by Project Duration

| Project Duration | Level 1 | Level 2 | Level 3 | Level 4 |
|------------------|---------|---------|---------|---------|
| < 1 week         | ✓       | ~       | ✗       | ✗       |
| 1 week - 1 month | ~       | ✓       | ~       | ✗       |
| 1-6 months       | ✗       | ✓       | ✓       | ~       |
| 6+ months        | ✗       | ~       | ✓       | ✓       |
| Multi-year       | ✗       | ✗       | ✓       | ✓       |

✓ = Recommended, ~ = Consider, ✗ = Not recommended

## Migration Path

Projects can migrate progressively:

```
Level 1 → Level 2:
  renv::init()  # 5 minutes

Level 2 → Level 3:
  zzcollab -M   # 30 seconds (minimal) or 4-6 minutes (standard)

Level 3 → Level 4:
  zzcollab -G   # Adds GitHub workflows (already done if using zzcollab)
```

No need to commit to Level 4 immediately - start at Level 2, add Docker when
needed for cross-platform work, add CI/CD when team grows.

# Practical Examples

## Example 1: Solo Exploratory Analysis

**Scenario**: Testing a new statistical method on small dataset.

**Duration**: 2 days

**Recommended Level**: Level 1

**Rationale**: Quick iteration more important than reproducibility. If method
shows promise, migrate to Level 2 for thorough analysis.

```r
# Just use global packages
install.packages("bootstrap")
library(bootstrap)

# Analyze and move on
```

## Example 2: Master's Thesis Analysis

**Scenario**: Student analyzing dataset for thesis. Will share code with
advisor. May extend analysis for publication.

**Duration**: 3-6 months

**Recommended Level**: Level 2

**Rationale**: Need to ensure advisor can reproduce results. Long enough that
packages might update during analysis.

```r
# Initialize renv
renv::init()
renv::install("tidyverse")
renv::install("lme4")

# Analysis code...

# Snapshot before sharing with advisor
renv::snapshot()

# Advisor runs:
renv::restore()  # Gets exact package versions
```

## Example 3: Multi-Site Climate Study

**Scenario**: Three universities collaborating on climate analysis. Different
platforms (Windows, Mac, Linux). Complex geospatial dependencies.

**Duration**: 2 years

**Recommended Level**: Level 3

**Rationale**: Cross-platform team requires Docker. Geospatial packages
(sf, terra) have complex system dependencies.

```bash
# Team lead setup
zzcollab -i -t climate-team -p precipitation -S -D ~/dotfiles

# Team members (any platform)
git clone https://github.com/climate-team/precipitation
cd precipitation
make docker-zsh  # Identical environment on all platforms

# Inside container - everyone has same GDAL, GEOS versions
```

## Example 4: Open Source R Package

**Scenario**: Developing R package for CRAN submission. Contributors from
around world. Must pass R CMD check on Windows/Mac/Linux.

**Duration**: Ongoing

**Recommended Level**: Level 4

**Rationale**: Multiple contributors require automated testing. CRAN submission
requires validation on multiple platforms.

```bash
# Package maintainer setup
zzcollab -i -t myname -p mypackage -S -D ~/dotfiles -G

# Every contributor push triggers:
# - R CMD check on Ubuntu
# - Test suite execution
# - Documentation validation
# - Dependency checking

# Pull requests show CI status
# Maintainer only merges if CI passes
```

## Example 5: Weekly Reporting Pipeline

**Scenario**: Automated weekly report generation from database. Runs on server.
Code rarely changes but must always work.

**Duration**: Ongoing

**Recommended Level**: Level 3 (optionally Level 4)

**Rationale**: Production deployment requires Docker. CI/CD useful if code
changes frequently, but may be overkill for stable pipeline.

```bash
# Setup with Docker for production
zzcollab -F -D ~/dotfiles  # Fast mode sufficient

# Deploy to server
docker build -t weekly-report .
docker run -v /data:/data weekly-report Rscript generate_report.R

# Add CI/CD later if code complexity grows
```

# Technical Details

## renv Isolation Mechanism

renv creates a project-specific library by:

1. **Installing packages to `renv/library/`** instead of global library
2. **Recording versions in `renv.lock`** (JSON format)
3. **Activating via `.Rprofile`** which sets `.libPaths()`

```r
# Before renv::init()
.libPaths()
# [1] "/usr/local/lib/R/site-library"  # Global library

# After renv::init()
.libPaths()
# [1] "/project/renv/library/R-4.3/x86_64-pc-linux-gnu"  # Project library
# [2] "/usr/local/lib/R/site-library"                    # Fallback
```

## Docker Isolation Mechanism

Docker creates isolated environment by:

1. **Base image** (rocker/r-ver:4.3.1) - specific R version
2. **System libraries** (GDAL, GEOS, etc.) installed via apt-get
3. **R packages** installed via Dockerfile instructions
4. **Project files** mounted as volume

```dockerfile
FROM rocker/r-ver:4.3.1
RUN apt-get update && apt-get install -y libgdal-dev
RUN R -e "install.packages('renv')"
WORKDIR /project
```

Container runs as isolated process with own filesystem, but project directory
is mounted for live editing.

## CI/CD Validation Mechanism

GitHub Actions validates by:

1. **Checking out code** from repository
2. **Building Docker container** from Dockerfile
3. **Running validation scripts** in container
4. **Reporting results** via GitHub interface

```yaml
# .github/workflows/r-package.yml
jobs:
  check:
    runs-on: ubuntu-latest
    container: rocker/tidyverse:latest
    steps:
      - uses: actions/checkout@v4
      - name: Validate dependencies
        run: Rscript validate_package_environment.R --quiet --fail-on-issues
```

# Common Pitfalls

## Level 2 Pitfalls (renv)

**Forgetting `renv::snapshot()`**:

```r
# Wrong workflow
renv::install("new-package")
# ... use package in code ...
git commit  # renv.lock not updated!

# Collaborator runs:
renv::restore()  # Doesn't get new-package
# Code fails with "package not found"

# Correct workflow
renv::install("new-package")
renv::snapshot()  # Update renv.lock
git add renv.lock
git commit
```

**Installing packages globally by accident**:

```r
# Wrong: Bypasses renv
install.packages("dplyr")  # Goes to global library

# Right: Uses project library
renv::install("dplyr")     # Goes to renv/library/
```

## Level 3 Pitfalls (Docker)

**File permission issues**:

```bash
# Inside container (running as root)
touch output.csv

# Outside container (your user)
rm output.csv  # Permission denied!

# Solution: Container should run as non-root user (zzcollab does this)
```

**Forgetting to exit container before git operations**:

```bash
# Wrong
make docker-zsh
git commit  # Runs inside container

# Right
make docker-zsh
# ... work ...
exit  # Exit container first
git commit  # Run on host
```

**Editing files outside container**:

Files edited on host (Mac/Windows) are visible in container, but some editors
create temp files that can cause issues. Best practice: edit on host, run in
container.

## Level 4 Pitfalls (CI/CD)

**Not testing locally before pushing**:

```bash
# Wrong workflow
git commit -m "Fix analysis"
git push  # CI fails, must fix and push again

# Right workflow
Rscript validate_package_environment.R --quiet
make docker-test
git commit -m "Fix analysis"
git push  # CI passes
```

**Ignoring CI failures**:

CI failures must be fixed immediately. Ignoring them leads to:
- Broken main branch
- Inability to merge pull requests
- Loss of confidence in tests

# Summary

Reproducibility is not binary - it exists on a spectrum. ZZCOLLAB provides
four levels of increasing reproducibility guarantees:

1. **Level 1** (Manual): Quick start, no guarantees
2. **Level 2** (renv): Package version guarantees
3. **Level 3** (renv + Docker): Complete environment guarantees
4. **Level 4** (renv + Docker + CI/CD): Automated validation guarantees

Choose the level appropriate for your project's:
- Duration
- Team size
- Platform diversity
- Publication requirements
- Maintenance needs

Start simple and migrate incrementally as needs evolve. You can always add
renv later, add Docker when needed, add CI/CD when the team grows.

The goal is reproducibility without unnecessary complexity.
