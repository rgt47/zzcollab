---
title: "Advanced Usage of {{PACKAGE_NAME}}"
author: "{{AUTHOR_NAME}} {{AUTHOR_LAST}}"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Advanced Usage of {{PACKAGE_NAME}}}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  fig.align = "center"
)

library({{PACKAGE_NAME}})
```

# Advanced Package Usage

This vignette demonstrates advanced usage patterns and techniques for getting the most out of {{PACKAGE_NAME}}. It assumes familiarity with the basic functionality covered in the "Getting Started" vignette.

# Advanced Data Processing

## Large Dataset Handling

When working with large datasets, {{PACKAGE_NAME}} functions are designed to be memory efficient:

```{r large-data}
# Simulate a larger dataset
set.seed(42)
large_data <- data.frame(
  id = 1:10000,
  measurement1 = rnorm(10000, mean = 100, sd = 15),
  measurement2 = rnorm(10000, mean = 50, sd = 8),
  measurement3 = rnorm(10000, mean = 200, sd = 25),
  category = sample(c("Type1", "Type2", "Type3", "Type4"), 10000, replace = TRUE),
  batch = sample(paste0("Batch_", 1:20), 10000, replace = TRUE)
)

# Efficient summarization of large datasets
system.time({
  large_summary <- summarize_data(
    large_data,
    columns = c("measurement1", "measurement2", "measurement3"),
    stats = c("mean", "sd", "min", "max", "n")
  )
})

print(large_summary)
```

## Batch Processing

For processing multiple datasets or subgroups:

```{r batch-processing}
# Function for batch processing
batch_analyze <- function(data, group_col, analysis_cols) {
  # Split data by groups
  groups <- unique(data[[group_col]])

  results <- list()

  for (group in groups) {
    group_data <- data[data[[group_col]] == group, ]

    # Analyze each group
    group_summary <- summarize_data(
      group_data,
      columns = analysis_cols,
      stats = c("mean", "sd", "n")
    )

    # Add group identifier
    group_summary$group <- group
    results[[group]] <- group_summary
  }

  # Combine results
  combined_results <- do.call(rbind, results)
  rownames(combined_results) <- NULL

  return(combined_results)
}

# Analyze by category
category_analysis <- batch_analyze(
  large_data,
  group_col = "category",
  analysis_cols = c("measurement1", "measurement2")
)

print(category_analysis)
```

# Custom Analysis Workflows

## Building Analysis Pipelines

Create reusable analysis pipelines using package functions:

```{r analysis-pipeline}
# Define a comprehensive analysis pipeline
analysis_pipeline <- function(data, target_vars, group_var = NULL) {
  results <- list()

  # Step 1: Data validation
  cat("Step 1: Validating data structure...\n")
  if (!is.data.frame(data)) {
    stop("Data must be a data.frame")
  }

  missing_vars <- setdiff(target_vars, names(data))
  if (length(missing_vars) > 0) {
    stop("Missing variables: ", paste(missing_vars, collapse = ", "))
  }

  results$validation <- list(
    n_rows = nrow(data),
    n_cols = ncol(data),
    target_vars = target_vars
  )

  # Step 2: Overall summary
  cat("Step 2: Computing overall summary...\n")
  results$overall_summary <- summarize_data(
    data,
    columns = target_vars,
    stats = c("mean", "median", "sd", "min", "max", "n", "missing")
  )

  # Step 3: Group-wise analysis (if requested)
  if (!is.null(group_var)) {
    cat("Step 3: Computing group-wise analysis...\n")
    results$group_analysis <- batch_analyze(data, group_var, target_vars)
  }

  # Step 4: Quality checks
  cat("Step 4: Performing quality checks...\n")
  quality_issues <- list()

  # Check for high missing data
  missing_rates <- sapply(data[target_vars], function(x) sum(is.na(x)) / length(x))
  high_missing <- names(missing_rates[missing_rates > 0.1])
  if (length(high_missing) > 0) {
    quality_issues$high_missing <- high_missing
  }

  results$quality_issues <- quality_issues

  # Add metadata
  results$metadata <- list(
    analysis_date = Sys.time(),
    package_version = packageVersion("{{PACKAGE_NAME}}"),
    r_version = R.version.string
  )

  cat("Analysis pipeline complete!\n")
  return(results)
}

# Run the pipeline
pipeline_results <- analysis_pipeline(
  large_data,
  target_vars = c("measurement1", "measurement2", "measurement3"),
  group_var = "category"
)

# Examine results
str(pipeline_results, max.level = 2)
```

## Custom Validation Functions

Build custom validation on top of package functions:

```{r custom-validation}
# Advanced validation function
validate_analysis_data <- function(data, required_cols, max_missing_rate = 0.05) {
  validation_results <- list()

  # Structure validation
  validation_results$is_dataframe <- is.data.frame(data)
  validation_results$has_rows <- nrow(data) > 0
  validation_results$has_required_cols <- all(required_cols %in% names(data))

  if (!validation_results$has_required_cols) {
    missing_cols <- setdiff(required_cols, names(data))
    validation_results$missing_columns <- missing_cols
  }

  # Data quality validation
  if (validation_results$has_required_cols) {
    # Use package function for detailed summary
    data_summary <- summarize_data(
      data,
      columns = required_cols,
      stats = c("n", "missing")
    )

    # Calculate missing rates
    data_summary$missing_rate <- data_summary$missing / data_summary$n

    # Check missing data thresholds
    high_missing <- data_summary$missing_rate > max_missing_rate
    validation_results$quality_passed <- !any(high_missing)

    if (any(high_missing)) {
      validation_results$high_missing_vars <- data_summary$variable[high_missing]
      validation_results$missing_rates <- data_summary$missing_rate[high_missing]
    }

    validation_results$data_summary <- data_summary
  }

  # Overall validation status
  validation_results$passed <- all(c(
    validation_results$is_dataframe,
    validation_results$has_rows,
    validation_results$has_required_cols,
    validation_results$quality_passed %||% TRUE
  ))

  return(validation_results)
}

# Test the validation function
validation_test <- validate_analysis_data(
  large_data,
  required_cols = c("measurement1", "measurement2", "id"),
  max_missing_rate = 0.01
)

if (validation_test$passed) {
  cat("✓ Data validation passed\n")
} else {
  cat("✗ Data validation failed\n")
  if (!validation_test$has_required_cols) {
    cat("  Missing columns:", paste(validation_test$missing_columns, collapse = ", "), "\n")
  }
  if (!is.null(validation_test$high_missing_vars)) {
    cat("  High missing data in:", paste(validation_test$high_missing_vars, collapse = ", "), "\n")
  }
}
```

# Performance Optimization

## Efficient Data Processing

Tips for optimizing performance with package functions:

```{r performance}
# Compare different approaches
library(microbenchmark)

# Create test data
test_data <- data.frame(
  x = rnorm(1000),
  y = rnorm(1000),
  z = rnorm(1000)
)

# Benchmark different summary approaches
if (requireNamespace("microbenchmark", quietly = TRUE)) {
  benchmark_results <- microbenchmark(
    # Full summary
    full_stats = summarize_data(test_data, stats = c("mean", "median", "sd", "min", "max", "n")),

    # Minimal summary
    minimal_stats = summarize_data(test_data, stats = c("mean", "n")),

    # Single column
    single_col = summarize_data(test_data, columns = "x", stats = c("mean", "sd")),

    times = 100
  )

  print(benchmark_results)
}
```

## Memory-Efficient Processing

For very large datasets, consider processing in chunks:

```{r memory-efficient}
# Function for chunk-wise processing
process_in_chunks <- function(data, chunk_size = 1000, analysis_cols) {
  n_rows <- nrow(data)
  n_chunks <- ceiling(n_rows / chunk_size)

  chunk_results <- list()

  for (i in seq_len(n_chunks)) {
    start_row <- (i - 1) * chunk_size + 1
    end_row <- min(i * chunk_size, n_rows)

    chunk_data <- data[start_row:end_row, , drop = FALSE]

    # Process chunk
    chunk_summary <- summarize_data(
      chunk_data,
      columns = analysis_cols,
      stats = c("mean", "n")
    )

    chunk_summary$chunk <- i
    chunk_results[[i]] <- chunk_summary
  }

  # Combine results
  combined <- do.call(rbind, chunk_results)

  # Calculate weighted averages
  final_results <- aggregate(
    cbind(mean * n, n) ~ variable,
    data = combined,
    FUN = sum
  )

  names(final_results) <- c("variable", "weighted_sum", "total_n")
  final_results$overall_mean <- final_results$weighted_sum / final_results$total_n

  return(final_results[, c("variable", "overall_mean", "total_n")])
}

# Test chunk processing
chunk_results <- process_in_chunks(
  large_data,
  chunk_size = 2000,
  analysis_cols = c("measurement1", "measurement2")
)

print(chunk_results)
```

# Integration Patterns

## Working with tidyverse

{{PACKAGE_NAME}} functions integrate well with tidyverse workflows:

```{r tidyverse-integration}
if (requireNamespace("dplyr", quietly = TRUE)) {
  library(dplyr)

  # Custom summarization function for dplyr
  dplyr_summarize <- function(.data, ...) {
    # Convert to data.frame if needed
    df_data <- as.data.frame(.data)

    # Use package function
    summary_result <- summarize_data(df_data, ...)

    return(summary_result)
  }

  # Use in dplyr pipeline
  tidyverse_results <- large_data %>%
    filter(measurement1 > 90) %>%
    select(measurement1, measurement2, measurement3) %>%
    dplyr_summarize(stats = c("mean", "sd", "n"))

  print(tidyverse_results)
}
```

## Custom S3 Methods

Extend package functionality with S3 methods:

```{r s3-methods}
# Create a custom class for analysis results
analysis_result <- function(data, summary, metadata) {
  result <- list(
    data = data,
    summary = summary,
    metadata = metadata
  )
  class(result) <- "analysis_result"
  return(result)
}

# Print method for analysis results
print.analysis_result <- function(x, ...) {
  cat("Analysis Result Object\n")
  cat("======================\n")
  cat("Data dimensions:", nrow(x$data), "×", ncol(x$data), "\n")
  cat("Variables analyzed:", nrow(x$summary), "\n")
  cat("Analysis date:", as.character(x$metadata$date), "\n\n")

  cat("Summary:\n")
  print(x$summary)
}

# Create an analysis result object
demo_result <- analysis_result(
  data = large_data,
  summary = summarize_data(large_data, columns = c("measurement1", "measurement2")),
  metadata = list(date = Sys.Date(), analyst = "{{AUTHOR_NAME}}")
)

print(demo_result)
```

# Advanced Error Handling

## Robust Analysis Functions

Build error-resistant analysis functions:

```{r robust-functions}
# Robust analysis with comprehensive error handling
robust_analysis <- function(data, target_cols, fallback_stats = c("mean", "n")) {
  result <- list()
  errors <- list()

  tryCatch({
    # Attempt full analysis
    result$full_analysis <- summarize_data(
      data,
      columns = target_cols,
      stats = c("mean", "median", "sd", "min", "max", "n", "missing")
    )
  }, error = function(e) {
    errors$full_analysis <<- e$message

    # Try fallback analysis
    tryCatch({
      result$fallback_analysis <<- summarize_data(
        data,
        columns = target_cols,
        stats = fallback_stats
      )
    }, error = function(e2) {
      errors$fallback_analysis <<- e2$message
    })
  })

  # Return results with error information
  return(list(
    results = result,
    errors = errors,
    success = length(result) > 0
  ))
}

# Test with problematic data
problematic_data <- data.frame(
  good_var = 1:10,
  all_na = rep(NA, 10),
  mixed = c(1:5, rep(NA, 5))
)

robust_result <- robust_analysis(
  problematic_data,
  target_cols = c("good_var", "all_na", "mixed")
)

if (robust_result$success) {
  print(robust_result$results)
} else {
  cat("Analysis failed. Errors:\n")
  print(robust_result$errors)
}
```

# Package Development Integration

## Using {{PACKAGE_NAME}} in Other Packages

Best practices for depending on {{PACKAGE_NAME}} in other packages:

```{r package-integration, eval = FALSE}
# In your DESCRIPTION file:
# Imports: {{PACKAGE_NAME}}

# In your package functions:
my_analysis_function <- function(data, ...) {
  # Use package functions with explicit namespace
  results <- {{PACKAGE_NAME}}::summarize_data(data, ...)

  # Add your custom processing
  # ...

  return(results)
}

# For re-exporting functions:
#' @importFrom {{PACKAGE_NAME}} summarize_data
#' @export
{{PACKAGE_NAME}}::summarize_data
```

## Testing with {{PACKAGE_NAME}}

Using package functions in test suites:

```{r testing-integration, eval = FALSE}
# Example testthat tests
test_that("my function produces expected output", {
  test_data <- data.frame(x = 1:10, y = 11:20)

  # Use package function for validation
  summary_result <- {{PACKAGE_NAME}}::summarize_data(
    test_data,
    stats = c("mean", "n")
  )

  expect_equal(nrow(summary_result), 2)
  expect_equal(summary_result$n, c(10, 10))
})
```

# Performance Monitoring

## Benchmarking Your Workflows

Monitor the performance of your analysis workflows:

```{r performance-monitoring}
# Function to benchmark analysis workflows
benchmark_workflow <- function(data_sizes = c(100, 1000, 10000)) {
  results <- data.frame(
    data_size = integer(),
    time_seconds = numeric(),
    memory_mb = numeric()
  )

  for (size in data_sizes) {
    # Create test data
    test_data <- data.frame(
      x = rnorm(size),
      y = rnorm(size),
      z = rnorm(size)
    )

    # Measure time and memory
    gc()  # Clean up memory
    start_time <- Sys.time()

    # Run analysis
    analysis_result <- summarize_data(test_data)

    end_time <- Sys.time()
    time_taken <- as.numeric(difftime(end_time, start_time, units = "secs"))

    # Add to results
    results <- rbind(results, data.frame(
      data_size = size,
      time_seconds = time_taken,
      memory_mb = NA  # Could use profmem package for detailed memory profiling
    ))
  }

  return(results)
}

# Run benchmark
benchmark_data <- benchmark_workflow()
print(benchmark_data)
```

# Best Practices Summary

## Recommendations for Advanced Users

1. **Validation First**: Always validate your data before analysis
2. **Error Handling**: Use robust error handling for production workflows
3. **Performance**: Profile your code and optimize bottlenecks
4. **Documentation**: Document your custom workflows and functions
5. **Testing**: Test your analysis pipelines thoroughly
6. **Reproducibility**: Use version control and document your environment

## Common Pitfalls

- **Memory Issues**: Process large datasets in chunks
- **Missing Data**: Always specify how to handle missing values
- **Type Coercion**: Be explicit about data types
- **Error Propagation**: Handle errors gracefully in batch processing

# Session Information

```{r session-info}
sessionInfo()
```